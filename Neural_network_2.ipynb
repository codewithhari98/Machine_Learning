{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-network-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVaoqS6TjkDTCrIaAYpU0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codewithhari98/Machine_Learning/blob/main/Neural_network_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8fgBIiO-50W9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6902bcd6-c0ef-4ca2-d5da-2734e29f74f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "weights:  [[-0.06840593  0.14503688 -0.08928376  0.15850501]\n",
            " [ 0.28367214  0.35226899  0.07809171 -0.37657678]\n",
            " [-0.19680188  0.35379274  0.05188079  0.13946606]\n",
            " [ 0.09220592  0.2172623  -0.29966389  0.42439393]\n",
            " [ 0.34807639  0.17512761  0.40682507 -0.4383075 ]]\n",
            "bias:  [[ 0.01407155  0.18582692 -0.19935951  0.2375246 ]]\n"
          ]
        }
      ],
      "source": [
        "# Idea1: create a global w and b of size L which is number of layers\n",
        "#https://www.youtube.com/watch?v=RSl87lqOXDE&ab_channel=CoreySchafer\n",
        "#https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce654\n",
        "#https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n",
        "import numpy as np\n",
        "class Layer:\n",
        "  def __init__(self,inputsize,outputsize):\n",
        "    self.input=inputsize\n",
        "    self.output=outputsize\n",
        "    self.weights = np.random.rand(inputsize, outputsize) - 0.5\n",
        "    self.bias = np.random.rand(1, outputsize) - 0.5\n",
        "  def forward_propagation(self, input):\n",
        "    return -1\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "    return -1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class linearlayer(Layer):\n",
        "  def forward_propagation(self,input):\n",
        "    self.input_data=input\n",
        "    f=np.dot(self.input_data, self.weights) + self.bias\n",
        "    return f\n",
        "  def backward_propagation(self,learning_rate,output_error):\n",
        "    #diff of function f wrt weights gives input data \n",
        "    dfw=self.input_data\n",
        "    dfx=self.weights\n",
        "    #calculating sensitivity of cost wrt previous activation layer\n",
        "    input_error = np.dot(output_error, dfx.T)\n",
        "    #calculating sensitivity of cost wrt change in weights\n",
        "    weights_error = np.dot(dfw.T, output_error)\n",
        "\n",
        "    self.weights=self.weights-learning_rate*weights_error\n",
        "    self.bias=self.bias-learning_rate*output_error\n",
        "    #this returns the sensitivity of the cost func wrt previous activation func\n",
        "    #which will be useful to calc the change in weights needed at inp\n",
        "    return input_error"
      ],
      "metadata": {
        "id": "eFII3yuofpYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class sigmoid(Layer):\n",
        "  def "
      ],
      "metadata": {
        "id": "1gg_ggjwhsvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=linearlayer(5,4)\n",
        "print(model1.output)\n",
        "#model=Layer()\n",
        "print(\"weights: \", model1.weights)\n",
        "print(\"bias: \",model1.bias)"
      ],
      "metadata": {
        "id": "BYBtmUr1f2bz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}